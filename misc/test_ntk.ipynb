{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dave6\\anaconda3\\envs\\dd\\lib\\site-packages\\torch\\_functorch\\deprecated.py:97: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.make_functional is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.functional_call instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('make_functional', 'torch.func.functional_call')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functorch import make_functional, vmap, vjp, jvp, jacrev\n",
    "device = 'cuda'\n",
    "\n",
    "class DenseNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully connected neural network\n",
    "    \"\"\"\n",
    "    def __init__(self, num_hidden_units):\n",
    "        super(DenseNN, self).__init__()\n",
    "        self.num_hidden_units = num_hidden_units\n",
    "        self.l1 = nn.Linear(784, num_hidden_units)\n",
    "        self.activation_fun = nn.ReLU()\n",
    "        self.l2 = nn.Linear(num_hidden_units, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.activation_fun(self.l1(x)))\n",
    "    \n",
    "#x_train = torch.randn(2, 784, device=device)\n",
    "\n",
    "\n",
    "transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            torch.flatten\n",
    "            ])\n",
    "data_rng = np.random.RandomState(12345)\n",
    "\n",
    "dataset1 = datasets.MNIST('./mnist_data', train=True, download=True,\n",
    "                    transform=transform)\n",
    "dataset2 = datasets.MNIST('./mnist_data', train=False, download=True,\n",
    "                    transform=transform)\n",
    "dataset1 = Subset(dataset1, data_rng.choice(len(dataset1), 500, replace=False))\n",
    "train_loader = DataLoader(dataset1, batch_size=len(dataset1), shuffle=True)\n",
    "i, (train_data, train_labels) = next(enumerate(train_loader))\n",
    "train_data = train_data.to(torch.device(\"cuda\"))\n",
    "\n",
    "test_loader = DataLoader(dataset2, batch_size=1000, shuffle=False)\n",
    "i, (test_data, test_labels) = next(enumerate(test_loader))\n",
    "test_data = test_data.to(torch.device(\"cuda\"))\n",
    "\n",
    "net = DenseNN(5).to(device)\n",
    "fnet, params = make_functional(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnet_single(params, x):\n",
    "    return fnet(params, x.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "def empirical_ntk_jacobian_contraction(fnet_single, params, x1, x2, compute=\"full\"):\n",
    "    # Compute J(x1)\n",
    "    jac1 = vmap(jacrev(fnet_single), (None, 0))(params, x1)\n",
    "    jac1 = [j.flatten(2) for j in jac1]\n",
    "    \n",
    "    # Compute J(x2)\n",
    "    jac2 = vmap(jacrev(fnet_single), (None, 0))(params, x2)\n",
    "    jac2 = [j.flatten(2) for j in jac2]\n",
    "    \n",
    "    # Compute J(x1) @ J(x2).T\n",
    "    einsum_expr = None\n",
    "    if compute == 'full':\n",
    "        einsum_expr = 'Naf,Mbf->NMab'\n",
    "    elif compute == 'trace':\n",
    "        einsum_expr = 'Naf,Maf->NM'\n",
    "    elif compute == 'diagonal':\n",
    "        einsum_expr = 'Naf,Maf->NMa'\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    result = torch.stack([torch.einsum(einsum_expr, j1, j2) for j1, j2 in zip(jac1, jac2)])\n",
    "    result = result.sum(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 500])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dave6\\anaconda3\\envs\\dd\\lib\\site-packages\\torch\\_functorch\\deprecated.py:80: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.jacrev is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.jacrev instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('jacrev')\n",
      "c:\\Users\\Dave6\\anaconda3\\envs\\dd\\lib\\site-packages\\torch\\_functorch\\deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "result = empirical_ntk_jacobian_contraction(fnet_single, params, train_data, train_data, compute=\"trace\")\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 10.0000,  10.0000,  10.0000,  ...,  10.0000,  10.0000,  10.0000],\n",
       "        [ 10.0000, 123.2491,  36.1689,  ...,  54.8940,  52.2415,  21.3331],\n",
       "        [ 10.0000,  36.1689, 149.8487,  ...,  76.0656,  23.9620,  10.0000],\n",
       "        ...,\n",
       "        [ 10.0000,  54.8940,  76.0656,  ..., 143.0298,  41.0103,  10.0000],\n",
       "        [ 10.0000,  52.2415,  23.9620,  ...,  41.0103, 107.5503,  30.5195],\n",
       "        [ 10.0000,  21.3331,  10.0000,  ...,  10.0000,  30.5195,  62.5905]],\n",
       "       device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(C=0.1, kernel=\"precomputed\")\n",
    "model = clf.fit(result.numpy(force=True), train_labels.numpy(force=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6,\n",
       "       6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2,\n",
       "       3, 5, 1, 2, 4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4,\n",
       "       6, 4, 3, 0, 7, 0, 2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3,\n",
       "       6, 1, 3, 6, 9, 3, 1, 4, 1, 7, 6, 9, 6, 0, 5, 4, 9, 9, 2, 1, 9, 4,\n",
       "       8, 7, 3, 9, 7, 4, 4, 4, 9, 2, 5, 4, 7, 6, 7, 9, 0, 5, 8, 5, 6, 6,\n",
       "       5, 7, 8, 1, 0, 1, 6, 4, 6, 7, 3, 1, 7, 1, 8, 2, 0, 2, 9, 9, 5, 5,\n",
       "       1, 5, 6, 0, 3, 4, 4, 6, 5, 4, 6, 5, 4, 5, 1, 4, 4, 7, 2, 3, 2, 7,\n",
       "       1, 8, 1, 8, 1, 8, 5, 0, 8, 9, 2, 5, 0, 1, 1, 1, 0, 9, 0, 3, 1, 6,\n",
       "       4, 2, 3, 6, 1, 1, 1, 3, 9, 5, 2, 9, 4, 5, 9, 3, 9, 0, 3, 6, 5, 5,\n",
       "       7, 2, 2, 7, 1, 2, 8, 4, 1, 7, 3, 3, 8, 8, 7, 9, 2, 2, 4, 1, 5, 9,\n",
       "       8, 7, 2, 3, 0, 4, 4, 2, 4, 1, 9, 5, 7, 7, 2, 8, 2, 6, 8, 5, 7, 7,\n",
       "       9, 1, 8, 1, 8, 0, 3, 0, 1, 9, 9, 4, 1, 8, 2, 1, 2, 9, 7, 5, 9, 2,\n",
       "       6, 4, 1, 5, 8, 2, 9, 2, 0, 4, 0, 0, 2, 8, 4, 7, 1, 2, 4, 0, 2, 7,\n",
       "       4, 3, 3, 0, 0, 3, 1, 9, 6, 5, 2, 5, 9, 2, 9, 3, 0, 4, 2, 0, 7, 1,\n",
       "       1, 2, 1, 5, 3, 3, 9, 7, 8, 6, 5, 6, 1, 3, 8, 1, 0, 5, 1, 3, 1, 5,\n",
       "       5, 6, 1, 8, 5, 1, 7, 9, 4, 6, 2, 2, 5, 0, 6, 5, 6, 3, 7, 2, 0, 8,\n",
       "       8, 5, 4, 1, 1, 4, 0, 3, 3, 7, 6, 1, 6, 2, 1, 9, 2, 8, 6, 1, 9, 5,\n",
       "       2, 5, 4, 4, 2, 8, 3, 8, 2, 4, 5, 0, 3, 1, 7, 7, 5, 7, 9, 7, 1, 9,\n",
       "       2, 1, 4, 2, 9, 2, 0, 4, 9, 1, 4, 8, 1, 8, 4, 5, 9, 8, 8, 3, 7, 6,\n",
       "       0, 0, 3, 0, 2, 6, 6, 4, 9, 3, 3, 3, 2, 3, 9, 1, 2, 6, 8, 0, 5, 6,\n",
       "       6, 6, 3, 8, 8, 2, 7, 5, 8, 9, 6, 1, 8, 4, 1, 2, 5, 9, 1, 9, 7, 5,\n",
       "       4, 0, 8, 9, 9, 1, 0, 5, 2, 3, 7, 8, 9, 4, 0, 6, 3, 9, 5, 2, 1, 3,\n",
       "       1, 3, 6, 5, 7, 4, 2, 2, 6, 3, 2, 6, 5, 4, 8, 9, 7, 1, 3, 0, 3, 8,\n",
       "       3, 1, 9, 3, 4, 4, 6, 4, 2, 1, 8, 2, 5, 4, 8, 8, 4, 0, 0, 2, 3, 2,\n",
       "       7, 7, 0, 8, 7, 4, 4, 7, 9, 6, 9, 0, 9, 8, 0, 4, 6, 0, 6, 3, 5, 4,\n",
       "       8, 3, 3, 9, 3, 3, 3, 7, 8, 0, 8, 2, 1, 7, 0, 6, 5, 4, 3, 8, 0, 9,\n",
       "       6, 3, 8, 0, 9, 9, 6, 8, 6, 8, 5, 7, 8, 6, 0, 2, 4, 0, 2, 2, 3, 1,\n",
       "       9, 7, 5, 1, 0, 8, 4, 6, 2, 6, 7, 9, 3, 2, 9, 8, 2, 2, 9, 2, 7, 3,\n",
       "       5, 9, 1, 8, 0, 2, 0, 5, 2, 1, 3, 7, 6, 7, 1, 2, 5, 8, 0, 3, 7, 2,\n",
       "       4, 0, 9, 1, 8, 6, 7, 7, 4, 3, 4, 9, 1, 9, 5, 1, 7, 3, 9, 7, 6, 9,\n",
       "       1, 3, 7, 8, 3, 3, 6, 7, 2, 8, 5, 8, 5, 1, 1, 4, 4, 3, 1, 0, 7, 7,\n",
       "       0, 7, 9, 4, 4, 8, 5, 5, 4, 0, 8, 2, 1, 0, 8, 4, 5, 0, 4, 0, 6, 1,\n",
       "       7, 3, 2, 6, 7, 2, 6, 9, 3, 1, 4, 6, 2, 5, 4, 2, 0, 6, 2, 1, 7, 3,\n",
       "       4, 1, 0, 5, 4, 3, 1, 1, 7, 4, 9, 9, 4, 8, 4, 0, 2, 4, 5, 1, 1, 6,\n",
       "       4, 7, 1, 9, 4, 2, 4, 1, 5, 5, 3, 8, 3, 1, 4, 5, 6, 8, 9, 4, 1, 5,\n",
       "       3, 8, 0, 3, 2, 5, 1, 2, 8, 3, 4, 4, 0, 8, 8, 3, 3, 1, 7, 3, 5, 9,\n",
       "       6, 3, 2, 6, 1, 3, 6, 0, 7, 2, 1, 7, 1, 4, 2, 4, 2, 1, 7, 9, 6, 1,\n",
       "       1, 2, 4, 8, 1, 7, 7, 4, 8, 0, 7, 3, 1, 3, 1, 0, 7, 7, 0, 3, 5, 5,\n",
       "       2, 7, 6, 6, 9, 2, 8, 3, 5, 2, 2, 5, 6, 0, 8, 2, 9, 2, 8, 8, 8, 8,\n",
       "       7, 4, 9, 3, 0, 6, 6, 3, 2, 1, 3, 2, 2, 9, 3, 0, 0, 5, 7, 8, 1, 4,\n",
       "       4, 6, 0, 2, 9, 1, 4, 7, 4, 7, 3, 9, 8, 8, 4, 7, 1, 2, 1, 2, 2, 3,\n",
       "       2, 3, 2, 3, 9, 1, 7, 4, 0, 3, 5, 5, 8, 6, 3, 2, 6, 7, 6, 6, 3, 2,\n",
       "       7, 8, 1, 1, 7, 5, 6, 4, 9, 5, 1, 3, 3, 4, 7, 8, 9, 1, 1, 6, 9, 1,\n",
       "       4, 4, 5, 4, 0, 6, 2, 2, 3, 1, 5, 1, 2, 0, 3, 8, 1, 2, 6, 7, 1, 6,\n",
       "       2, 3, 9, 0, 1, 2, 2, 0, 8, 9], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.numpy(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dave6\\anaconda3\\envs\\dd\\lib\\site-packages\\torch\\_functorch\\deprecated.py:80: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.jacrev is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.func.jacrev instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('jacrev')\n",
      "c:\\Users\\Dave6\\anaconda3\\envs\\dd\\lib\\site-packages\\torch\\_functorch\\deprecated.py:58: UserWarning: We've integrated functorch into PyTorch. As the final step of the integration, functorch.vmap is deprecated as of PyTorch 2.0 and will be deleted in a future version of PyTorch >= 2.3. Please use torch.vmap instead; see the PyTorch 2.0 release notes and/or the torch.func migration guide for more details https://pytorch.org/docs/master/func.migrating.html\n",
      "  warn_deprecated('vmap', 'torch.vmap')\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(empirical_ntk_jacobian_contraction(fnet_single, params, test_data, train_data, compute=\"trace\").numpy(force=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.753"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p == test_labels.numpy(force=True)) / len(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
